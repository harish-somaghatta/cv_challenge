{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7813a3ac",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Task 2: Multi-class Classification\n",
    "Author: Harish Somaghatta\n",
    "Description: Classification of surface defects of the hot-rolled steel strip\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c9bacb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed3b917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
  
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22351c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6\n"
     ]
    }
   ],
   "source": [
    "image_folder = r\"archive\\NEU-DET\\train\\images\"\n",
    "\n",
    "# Get the number of folders(n_classes) within the \"images\" folder\n",
    "items = os.listdir(image_folder)\n",
    "\n",
    "n_classes = 0\n",
    "# Loop through the items and count the number of folders\n",
    "for item in items:\n",
    "    item_path = os.path.join(image_folder, item)\n",
    "    if os.path.isdir(item_path):\n",
    "        n_classes += 1\n",
    "\n",
    "print(f\"Number of classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2f17437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that you are in correct path (base folder path) \n",
    "\n",
    "# path for the training output TFRecords folder\n",
    "train_output_tfrecords = os.path.join(folder_path, \"train_output.tfrecords\")\n",
    "\n",
    "# path for the testing output TFRecords folder\n",
    "test_output_tfrecords = os.path.join(folder_path, \"test_output.tfrecords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f83b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary specifying the necessary features in a TFRecord example\n",
    "image_feature_desc = {\n",
    "    'image/encodedrawdata': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "200f41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _parse_data(unparsed_example):\n",
    "    \"\"\"\n",
    "    Parses a single TFRecord example.\n",
    "\n",
    "    Parameters:\n",
    "        unparsed_example (tf.Tensor): The serialized TFRecord example.\n",
    "\n",
    "    Returns:\n",
    "        Parsed example containing image features and labels.\n",
    "    \"\"\"\n",
    "    return tf.io.parse_example(unparsed_example, image_feature_desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24734099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_str_to_pixel(parsed_example):\n",
    "    \"\"\"\n",
    "    Decodes the encoded image and extracts the label from TFRecord example.\n",
    "\n",
    "    Parameters:\n",
    "        parsed_example (dict): Parsed TFRecord example containing image and label information.\n",
    "\n",
    "    Returns:\n",
    "        The label and the decoded image will be returned.\n",
    "    \"\"\"\n",
    "    decoded_image = tf.io.decode_jpeg(parsed_example['image/encodedrawdata'])\n",
    "    label = parsed_example['image/object/class/label']\n",
    "\n",
    "    return label, decoded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc758ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_extract(filepath):\n",
    "    \"\"\"\n",
    "    Loads and extracts data from TFRecord files.\n",
    "\n",
    "    Parameters:\n",
    "        filepath (str): Filepath of list of TFRecord files.\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: A dataset containing parsed and decoded data.\n",
    "    \"\"\"\n",
    "    # Create a TFRecord dataset \n",
    "    dataset = tf.data.TFRecordDataset(filepath)\n",
    "    # Apply the parsing function to each example in the dataset\n",
    "    dataset = dataset.map(_parse_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    # Apply the decoding function to each example in the dataset\n",
    "    dataset = dataset.map(_bytes_str_to_pixel, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36da2225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the file paths\n",
    "tfrecord_files_train = []\n",
    "\n",
    "# Iterate through the files in the train_output_tfrecords directory\n",
    "for file in os.listdir(train_output_tfrecords):\n",
    "    # Check if the file has .tfrecord extension\n",
    "    if file.endswith(\".tfrecord\"):\n",
    "        # Make the full file path and append it to the list\n",
    "        tfrecord_path = os.path.join(train_output_tfrecords, file)\n",
    "        tfrecord_files_train.append(tfrecord_path)\n",
    "\n",
    "# Initialize an empty list to store the datasets\n",
    "all_datasets_train = []\n",
    "\n",
    "# Iterate through the TFRecord files and load each dataset\n",
    "for file in tfrecord_files_train:\n",
    "    # Load and extract the dataset from the current file\n",
    "    current_dataset = load_and_extract(file)\n",
    "    \n",
    "    # Append the dataset to the list\n",
    "    all_datasets_train.append(current_dataset)\n",
    "\n",
    "# Create a TensorFlow dataset from a list of datasets (all_datasets_train)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(all_datasets_train)\n",
    "# Flatten the dataset of datasets into a single dataset using flat_map\n",
    "train_dataset = train_dataset.flat_map(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f111b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "# Extract labels and images for training\n",
    "train_labels = []\n",
    "train_images = []\n",
    "\n",
    "# Iterate through the elements of the flattened train_dataset\n",
    "for label, decode_img in train_dataset:\n",
    "    # Append the label values to train_labels\n",
    "    train_labels.append(label.values.numpy()[0])\n",
    "    # Append the decoded image to train_images\n",
    "    train_images.append(decode_img)\n",
    "\n",
    "# Convert train_labels to a TensorFlow constant tensor(compatibility with other TensorFlow operations and functions)\n",
    "train_labels = tf.constant(train_labels)\n",
    "\n",
    "# Stack the train_images into a single TensorFlow tensor( To make the data in a consistent structure )\n",
    "train_images = tf.stack(train_images)\n",
    "print(train_images.shape)\n",
    "\n",
    "# Get image dimensions\n",
    "image_height, image_width, n_color_channels = train_images.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2628f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the base model (Xception) for feature extraction\n",
    "base_model = tf.keras.applications.Xception(\n",
    "    input_shape=(image_height, image_width, n_color_channels),   # Specify input image dimensions\n",
    "    include_top=False,  # Exclude the fully-connected layers at the top\n",
    "    weights=\"imagenet\"  # Use pre-trained weights from ImageNet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5307e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Sequential model combining the base Xception model with additional layers for classification\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,  # Add the pre-trained Xception base model for feature extraction\n",
    "    layers.BatchNormalization(),   # Normalize the activations of the previous layers\n",
    "    layers.GlobalAveragePooling2D(), # Global Average Pooling to reduce dimensions\n",
    "    layers.Dense(8, activation='relu'),  # Dense layer with ReLU activation for non-linearity\n",
    "    layers.Dropout(0.4),  # Dropout layer to reduce overfitting during training\n",
    "    layers.Dense(n_classes, activation='softmax') # Output layer with softmax activation for multi-class classification\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9617e477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with optimizer, loss function, and evaluation metric\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),  \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # Sparse categorical crossentropy loss for multi-class classification\n",
    "    metrics=['accuracy']  # Check accuracy during model training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8224b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shari\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:5714: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1058s 23s/step - loss: 1.0088 - accuracy: 0.6090\n",
      "Epoch 2/2\n",
      "45/45 [==============================] - 1016s 23s/step - loss: 0.5752 - accuracy: 0.7472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x18a07ac5e50>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "945127f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the TFRecord files\n",
    "tfrecord_files_test = []\n",
    "\n",
    "# Loop through all files and filter for those ending with \".tfrecord\"\n",
    "for file in os.listdir(test_output_tfrecords):\n",
    "    if file.endswith(\".tfrecord\"):\n",
    "        # Create the full path and append to the list\n",
    "        tfrecord_files_test.append(os.path.join(test_output_tfrecords, file))\n",
    "# Load all TFRecord datasets into a list for testing\n",
    "all_datasets_test = [load_and_extract(file) for file in tfrecord_files_test]\n",
    "\n",
    "# Concatenate all datasets in the list\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(all_datasets_test)\n",
    "test_dataset = test_dataset.flat_map(lambda x: x)\n",
    "\n",
    "# Extract labels and images for testing\n",
    "test_labels = []\n",
    "test_images = []\n",
    "for label, decode_img in test_dataset:\n",
    "    test_labels.append(label.values.numpy()[0])\n",
    "    test_images.append(decode_img)\n",
    "\n",
    "test_labels = tf.one_hot(test_labels, depth=n_classes) \n",
    "test_images = tf.stack(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7158069e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 31s 2s/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test dataset\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49e8e0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.824999988079071\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted class indices \n",
    "predicted_indices = tf.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the true class indices from the one-hot encoded test labels\n",
    "true_indices = tf.argmax(test_labels, axis=1)\n",
    "\n",
    "# Compare the predicted and true class indices(Gives True or False)\n",
    "correct_predictions = tf.equal(predicted_indices, true_indices)\n",
    "\n",
    "# Convert true to 1 and false to 0\n",
    "correct_predictions_float = tf.cast(correct_predictions, tf.float32)\n",
    "\n",
    "# Calculate the mean of the float tensor to get the overall accuracy\n",
    "accuracy = tf.reduce_mean(correct_predictions_float)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4260eead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
